Model Overview
The emotion detection model uses Convolutional Neural Networks (CNNs) to process speech signals, 
learning hierarchical patterns from spectrograms. The architecture consists of convolutional layers for feature 
extraction, pooling layers for dimensionality reduction, and fully connected layers for classification. 
Activation functions like ReLU and softmax enhance performance, while dropout prevents overfitting.
Libraries and Tools:
TensorFlow & Keras – Model building and training 
Librosa – Audio feature extraction (MFCCs, spectrograms) 
Matplotlib – Visualization (loss curves, accuracy graphs) 
NumPy – Numerical operations and matrix handling 
audiomentation
